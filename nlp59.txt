Natural language processing From Wikipedia
Wikipedia
the free encyclopedia Natural language processing (NLP) is a field of computer science , artificial intelligence , and linguistics concerned with the interactions between computers and human (natural) languages .
the free encyclopedia Natural language processing (NLP)
NLP)
a field of computer science , artificial intelligence , and linguistics concerned with the interactions between computers and human (natural) languages
a field of computer science , artificial intelligence , and linguistics concerned with the interactions between computers and human (natural) languages
a field of computer science
computer science
artificial intelligence , and linguistics concerned with the interactions between computers and human (natural) languages
linguistics concerned with the interactions between computers and human (natural) languages
linguistics concerned with the interactions between computers and human (natural) languages
the interactions between computers and human (natural) languages
the interactions between computers and human (natural) languages
computers and human (natural) languages
computers and human (natural) languages
human (natural) languages
such
NLP is related to the area of humani-computer interaction .
the area of humani-computer interaction
the area of humani-computer interaction
humani-computer interaction
Many challenges in NLP involve natural language understanding , that is , enabling computers to derive meaning from human or natural language input
Many challenges in NLP
NLP
natural language understanding , that is , enabling computers to derive meaning from human or natural language input
natural language understanding , that is ,
computers to derive meaning from human or natural language input
meaning from human or natural language input
human or natural language input
others involve natural language generation
natural language generation
History The history of NLP generally starts in the 1950s , although work can be found from earlier periods .
History The history of NLP
NLP
the 1950s
work can be found from earlier periods
earlier periods
1950
Alan Turing published an article titled `` Computing Machinery and Intelligence '' which proposed what is now called the Turing test as a criterion of intelligence .
an article titled `` Computing Machinery and Intelligence '' which proposed what is now called the Turing test as a criterion of intelligence
an article titled `` Computing Machinery and Intelligence '' which proposed what is now called the Turing test as a criterion of intelligence
Computing Machinery and Intelligence ''
the Turing test as a criterion of intelligence
a criterion of intelligence
a criterion of intelligence
intelligence
The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English .
The Georgetown experiment in 1954
1954
fully automatic translation of more than sixty Russian sentences into English
fully automatic translation of more than sixty Russian sentences
more than sixty Russian sentences
English
The authors claimed that within three or five years , machine translation would be a solved problem .
three or five years
machine translation would be a solved problem
a solved problem
real progress was much slower
the ALPAC report in 1966 , which found that ten year long research had failed to fulfill the expectations
the ALPAC report in 1966 , which found that ten year long research had failed to fulfill the expectations
1966
ten year long research had failed to fulfill the expectations
long research had failed to fulfill the expectations
the expectations
machine
translation was dramatically reduced
Little further research in machine translation was conducted until the late 1980s , when the first statistical machine translation systems were developed .
Little further research in machine translation
machine translation
the late 1980s , when the first statistical machine translation systems were developed
the late 1980s , when the first statistical machine translation systems were developed
the first statistical machine translation systems were developed
the first statistical machine translation systems
translation systems
Some notably successful NLP systems developed in the 1960s were SHRDLU , a natural language system working in restricted `` blocks worlds '' with restricted vocabularies
Some notably successful NLP systems developed in the 1960s
the 1960s
SHRDLU , a natural language system working in restricted `` blocks worlds '' with restricted vocabularies
SHRDLU , a natural language system working in restricted `` blocks worlds '' with restricted vocabularies
a natural language system working in restricted `` blocks worlds '' with restricted vocabularies
a natural language system working in restricted `` blocks worlds '' with restricted vocabularies
restricted `` blocks worlds ''
restricted `` blocks worlds ''
blocks worlds ''
restricted vocabularies
ELIZA , a simulation of a Rogerian psychotherapist , written by Joseph Weizenbaum between 1964 to 1966
ELIZA , a simulation of a Rogerian psychotherapist ,
a simulation of a Rogerian psychotherapist ,
a simulation of a Rogerian psychotherapist
a Rogerian psychotherapist
Joseph Weizenbaum between 1964 to 1966
Joseph Weizenbaum between 1964 to 1966
1964 to 1966
almost no information about human thought or emotion
human thought or emotion
ELIZA sometimes provided a startlingly human-like interaction .
a startlingly human-like interaction
the `` patient '' exceeded the very small knowledge base
the very small knowledge base
ELIZA might provide a generic response , for example , responding to `` My head hurts '' with `` Why do you say your head hurts ? ''
a generic response , for example , responding to `` My head hurts '' with `` Why do you say your head hurts ? ''
a generic response , for example , responding to `` My head hurts
example
My head
you say your head hurts
your head hurts
.
the 1970s
many programmers began to write ` conceptual ontologies ' , which structured real-world information into computer-understandable data .
conceptual ontologies ' , which structured real-world information into computer-understandable data
conceptual ontologies ' , which structured real-world information into computer-understandable data
conceptual ontologies '
ontologies '
real-world information into computer-understandable data
computer-understandable data
Examples are MARGIE (Schank , 1975) , SAM (Cullingford , 1978) , PAM (Wilensky , 1978) , TaleSpin (Meehan , 1976) , QUALM (Lehnert , 1977) , Politics (Carbonell , 1979) , and Plot Units (Lehnert 1981) .
MARGIE (Schank , 1975) , SAM (Cullingford , 1978) , PAM (Wilensky , 1978) , TaleSpin (Meehan , 1976) , QUALM (Lehnert , 1977) , Politics (Carbonell , 1979) , and Plot Units (Lehnert 1981)
MARGIE (Schank , 1975) , SAM (Cullingford , 1978) , PAM (Wilensky , 1978) , TaleSpin (Meehan , 1976) , QUALM (Lehnert , 1977) , Politics (Carbonell , 1979) , and Plot Units (Lehnert 1981)
MARGIE (Schank , 1975)
Schank , 1975)
1975)
SAM (Cullingford , 1978) , PAM (Wilensky , 1978) , TaleSpin (Meehan , 1976) , QUALM (Lehnert , 1977) , Politics (Carbonell , 1979) , and Plot Units (Lehnert 1981)
SAM (Cullingford , 1978) , PAM (Wilensky , 1978) , TaleSpin (Meehan , 1976) , QUALM (Lehnert , 1977) , Politics (Carbonell , 1979) , and Plot Units (Lehnert 1981)
SAM (Cullingford , 1978)
Cullingford , 1978)
1978)
PAM (Wilensky , 1978) , TaleSpin (Meehan , 1976) , QUALM (Lehnert , 1977) , Politics (Carbonell , 1979) , and Plot Units (Lehnert 1981)
PAM (Wilensky , 1978)
Wilensky , 1978)
1978)
TaleSpin (Meehan , 1976) , QUALM (Lehnert , 1977) , Politics (Carbonell , 1979) , and Plot Units (Lehnert 1981)
TaleSpin (Meehan , 1976)
Meehan , 1976)
1976)
QUALM (Lehnert , 1977) , Politics (Carbonell , 1979) , and Plot Units (Lehnert 1981)
QUALM (Lehnert , 1977)
Lehnert , 1977)
1977)
Politics (Carbonell , 1979) , and Plot Units (Lehnert 1981)
Politics (Carbonell , 1979)
Carbonell , 1979)
1979)
Plot Units (Lehnert 1981)
Plot Units (Lehnert 1981)
Lehnert 1981)
this time
many chatterbots were written including PARRY , Racter , and Jabberwacky .
PARRY , Racter , and Jabberwacky
the 1980s
most NLP systems were based on complex sets of hand-written rules .
complex sets of hand-written rules
complex sets of hand-written rules
hand-written rules
the late 1980s
there was a revolution in NLP with the introduction of machine learning algorithms for language processing .
a revolution in NLP with the introduction of machine learning algorithms for language processing
a revolution in NLP
NLP
the introduction of machine learning algorithms for language processing
the introduction of machine learning algorithms for language processing
machine learning algorithms for language processing
machine learning algorithms for language processing
language processing
This was due to both the steady increase in computational power resulting from Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar) , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing .
both the steady increase
computational power resulting from Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar) , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing
computational power resulting from Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar) , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing
Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar) , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing
Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar) , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing
Moore 's Law
the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar) , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing
the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar) , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing
the dominance of Chomskyan theories
the dominance of Chomskyan theories
Chomskyan theories
linguistics (e.g. transformational grammar)
linguistics (e.g. transformational grammar)
e.g. transformational grammar)
e.g. transformational grammar
transformational grammar
theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing
the sort of corpus linguistics that underlies the machine-learning approach to language processing
the sort of corpus linguistics that underlies the machine-learning approach to language processing
corpus linguistics
the machine-learning approach to language processing
language processing
Some of the earliest-used machine learning algorithms , such as decision trees , produced systems of hard if-then rules similar to existing hand-written rules .
Some of the earliest-used machine learning algorithms , such as decision trees ,
the earliest-used machine learning algorithms , such as decision trees ,
the earliest-used machine learning algorithms , such as decision trees ,
algorithms , such as decision trees ,
algorithms , such as decision trees ,
decision trees
systems of hard if-then rules similar to existing hand-written rules
systems of hard if-then rules similar to existing hand-written rules
hard if-then rules similar to existing hand-written rules
hard if-then rules similar to existing hand-written rules
existing hand-written rules
Part of speech tagging introduced the use of Hidden Markov Models to NLP
Part of speech
speech
the use of Hidden Markov Models to NLP
the use of Hidden Markov Models
Hidden Markov Models
NLP
research has focused on statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to the features making up the input data
statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to the features making up the input data
statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to the features making up the input data
soft , probabilistic decisions based on attaching real-valued weights to the features making up the input data
real-valued weights to the features making up the input data
the features making up the input data
the features making up the input data
the input data
The cache language models upon which many speech recognition systems now rely are examples of such statistical models .
The cache language models upon which many speech recognition systems now rely
many speech recognition systems now rely
examples of such statistical models
examples of such statistical models
such statistical models
Such models are generally more robust when given unfamiliar input , especially input that contains errors (as is very common for real-world data) , and produce more reliable results when integrated into a larger system comprising multiple subtasks .
unfamiliar input , especially input that contains errors (as is very common for real-world data) ,
unfamiliar input , especially input that contains errors (as is very common for real-world data) ,
input that contains errors (as is very common for real-world data) ,
input that contains errors (as is very common for real-world data)
errors (as is very common for real-world data)
errors (as is very common for real-world data)
real-world data
more reliable results when integrated into a larger system comprising multiple subtasks
a larger system comprising multiple subtasks
a larger system comprising multiple subtasks
multiple subtasks
Many of the notable early successes occurred in the field of machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed .
Many of the notable early successes
the notable early successes
the field of machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed
the field of machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed
machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed
machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed
IBM Research
more complicated statistical models were developed
These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government .
advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government
advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government
existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government
existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government
the Parliament of Canada and the European Union
the Parliament of Canada and the European Union
Canada and the European Union
Canada and the European Union
the European Union
a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government
a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government
laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government
laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government
the translation of all governmental proceedings
the translation of all governmental proceedings
all governmental proceedings
all official languages of the corresponding systems of government
all official languages of the corresponding systems of government
the corresponding systems of government
the corresponding systems of government
government
most other systems depended on corpora
corpora
the tasks implemented by these systems , which was (and often continues to be)
the tasks implemented by these systems , which was (and often continues to be)
these systems , which was (and often continues to be)
these systems , which was (and often continues to be)
a major limitation in the success of these systems .
a major limitation in the success of these systems
the success of these systems
the success of these systems
these systems
a result
a great deal of research has gone into methods of more effectively learning from limited amounts of data .
a great deal of research
research
methods of more effectively learning from limited amounts of data
methods of more effectively learning from limited amounts of data
more effectively learning from limited amounts of data
more effectively learning from limited amounts of data
limited amounts of data
limited amounts of data
data
Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms .
unsupervised and semi-supervised learning algorithms
Such algorithms are able to learn from data that has not been hand-annotated with the desired answers , or using a combination of annotated and non-annotated data .
data that has not been hand-annotated with the desired answers
data that has not been hand-annotated with the desired answers
the desired answers
a combination of annotated and non-annotated data
a combination of annotated and non-annotated data
annotated and non-annotated data
this task is much more difficult than supervised learning , and typically produces less accurate results for a given amount of input data .
supervised learning
less accurate results for a given amount of input data
less accurate results for a given amount of input data
a given amount of input data
a given amount of input data
input data
there is an enormous amount of non-annotated data available (including , among other things , the entire content of the World Wide Web) , which can often make up for the inferior results .
an enormous amount of non-annotated data available (including , among other things , the entire content of the World Wide Web) , which can often make up for the inferior results
an enormous amount of non-annotated data available (including , among other things , the entire content of the World Wide Web) , which can often make up for the inferior results
an enormous amount of non-annotated data available
non-annotated data available
non-annotated data available
other things
the entire content of the World Wide Web
the entire content of the World Wide Web
the World Wide Web
the inferior results
NLP using machine learning Modern NLP algorithms are based on machine learning , especially statistical machine learning .
NLP using machine learning Modern NLP algorithms
machine learning Modern NLP algorithms
machine learning , especially statistical machine learning
machine learning , especially statistical machine learning
statistical machine learning
The paradigm of machine learning is different from that of most prior attempts at language processing .
The paradigm of machine learning
machine learning
that of most prior attempts
that of most prior attempts
most prior attempts
language processing
implementations of language-processing tasks typically involved the direct hand coding of large sets of rules .
implementations of language-processing tasks
language-processing tasks
the direct hand coding of large sets of rules
the direct hand coding of large sets of rules
large sets of rules
large sets of rules
rules
The machine-learning paradigm calls instead for using general learning algorithms - often , although not always , grounded in statistical inference - to automatically learn such rules through the analysis of large corpora of typical real-world examples .
general learning algorithms - often , although not always , grounded in statistical inference
general learning algorithms - often
statistical inference
such rules through the analysis of large corpora of typical real-world examples
the analysis of large corpora of typical real-world examples
the analysis of large corpora of typical real-world examples
large corpora of typical real-world examples
large corpora of typical real-world examples
typical real-world examples
A corpus (plural , `` corpora '') is a set of documents (or sometimes , individual sentences) that have been hand-annotated with the correct values to be learned .
A corpus (plural , `` corpora '')
plural , `` corpora '')
plural , `` corpora ''
`` corpora ''
a set of documents (or sometimes , individual sentences) that have been hand-annotated with the correct values to be learned
a set of documents (or sometimes , individual sentences) that have been hand-annotated with the correct values to be learned
documents (or sometimes , individual sentences) that have been hand-annotated with the correct values to be learned
documents (or sometimes , individual sentences) that have been hand-annotated with the correct values to be learned
individual sentences)
the correct values
Many different classes of machine learning algorithms have been applied to NLP tasks .
Many different classes of machine learning algorithms
machine learning algorithms
NLP tasks
These algorithms take as input a large set of `` features '' that are generated from the input data .
as input a large set of `` features '' that are generated from the input data
a large set of `` features '' that are generated from the input data
a large set of `` features '' that are generated from the input data
`` features '' that are generated from the input data
`` features '' that are generated from the input data
the input data
Some of the earliest-used algorithms , such as decision trees , produced systems of hard if-then rules similar to the systems of hand-written rules that were then common .
Some of the earliest-used algorithms , such as decision trees ,
the earliest-used algorithms
decision trees
systems of hard if-then rules similar to the systems of hand-written rules that were then common
systems of hard if-then rules similar to the systems of hand-written rules that were then common
hard if-then rules similar to the systems of hand-written rules that were then common
hard if-then rules similar to the systems of hand-written rules that were then common
the systems of hand-written rules that were then common
the systems of hand-written rules that were then common
hand-written rules
research has focused on statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to each input feature .
statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to each input feature
statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to each input feature
soft , probabilistic decisions based on attaching real-valued weights to each input feature
real-valued weights to each input feature
each input feature
Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one , producing more reliable results when such a model is included as a component of a larger system .
the advantage that they can express the relative certainty of many different possible answers rather than only one , producing more reliable results when such a model is included as a component of a larger system
they can express the relative certainty of many different possible answers rather than only one
the relative certainty of many different possible answers rather than only one
the relative certainty of many different possible answers rather than only one
many different possible answers rather than only one
many different possible answers rather than only one
only one
more reliable results when such a model is included as a component of a larger system
such a model is included as a component of a larger system
a component of a larger system
a component of a larger system
a larger system
Systems based on machine-learning algorithms have many advantages over hand-produced rules
Systems based on machine-learning algorithms
machine-learning algorithms
many advantages over hand-produced rules
many advantages over hand-produced rules
hand-produced rules
The learning procedures used during machine learning automatically focus on the most common cases , whereas when writing rules by hand it is often not obvious at all where the effort should be directed
The learning procedures used during machine learning
machine learning
the most common cases , whereas when writing rules by hand it is often not obvious at all where the effort should be directed
the most common cases , whereas when writing rules by hand it is often not obvious at all where the effort should be directed
rules by hand
hand
it is often not obvious at all where the effort should be directed
all
the effort should be directed
Automatic learning procedures can make use of statistical inference algorithms to produce models that are robust to unfamiliar input (e.g. containing words or structures that have not been seen before) and to erroneous input (e.g. with misspelled words or words accidentally omitted) .
Automatic learning procedures
procedures
use of statistical inference algorithms to produce models that are robust to unfamiliar input (e.g. containing words or structures that have not been seen before) and to erroneous input (e.g. with misspelled words or words accidentally omitted)
use of statistical inference algorithms
statistical inference algorithms
models that are robust to unfamiliar input (e.g. containing words or structures that have not been seen before) and to erroneous input (e.g. with misspelled words or words accidentally omitted)
models that are robust to unfamiliar input (e.g. containing words or structures that have not been seen before) and to erroneous input (e.g. with misspelled words or words accidentally omitted)
unfamiliar input
words or structures that have not been seen before
words or structures that have not been seen before
erroneous input (e.g. with misspelled words or words accidentally omitted)
e.g. with misspelled words or words accidentally omitted)
e.g. with misspelled words or words accidentally omitted
words or words accidentally omitted
words or words accidentally omitted
such input gracefully with hand-written rules -- or more generally
such input gracefully with hand-written rules -- or more
hand-written rules
systems of hand-written rules that make soft decisions -- extremely difficult , error-prone and time-consuming
systems of hand-written rules that make soft decisions -- extremely difficult , error-prone and time-consuming
hand-written rules
soft decisions -- extremely difficult , error-prone and time-consuming
soft decisions -- extremely difficult , error-prone and time-consuming
Systems based on automatically learning the rules can be made more accurate simply by supplying more input data .
Systems based on automatically learning the rules
the rules
more input data
systems based on hand-written rules can only be made more accurate by increasing the complexity of the rules , which is a much more difficult task .
systems based on hand-written rules
hand-written rules
the complexity of the rules , which is a much more difficult task
the complexity of the rules , which is a much more difficult task
the rules , which is a much more difficult task
the rules , which is a much more difficult task
a much more difficult task
there is a limit to the complexity of systems based on hand-crafted rules , beyond which the systems become more and more unmanageable .
a limit to the complexity of systems based on hand-crafted rules , beyond which the systems become more and more unmanageable
a limit to the complexity of systems based on hand-crafted rules , beyond which the systems become more and more unmanageable
the complexity of systems based on hand-crafted rules , beyond which the systems become more and more unmanageable
the complexity of systems based on hand-crafted rules , beyond which the systems become more and more unmanageable
systems based on hand-crafted rules , beyond which the systems become more and more unmanageable
systems based on hand-crafted rules , beyond which the systems become more and more unmanageable
hand-crafted rules , beyond which the systems become more and more unmanageable
hand-crafted rules , beyond which the systems become more and more unmanageable
the systems become more and more unmanageable
more data to input to machine-learning systems
input
machine-learning systems
a corresponding increase in the number of man-hours worked
a corresponding increase in the number of man-hours
the number of man-hours
the number of man-hours
man-hours
significant increases in the complexity of the annotation process
significant increases in the complexity of the annotation process
the complexity of the annotation process
the complexity of the annotation process
the annotation process
The subfield of NLP devoted to learning approaches is known as Natural Language Learning (NLL) and its conference CoNLL and peak body SIGNLL are sponsored by ACL , recognizing also their links with Computational Linguistics and Language Acquisition .
The subfield of NLP devoted to learning approaches is known as Natural Language Learning (NLL) and its conference CoNLL and peak body SIGNLL
NLP devoted to learning approaches is known as Natural Language Learning (NLL) and its conference CoNLL and peak body SIGNLL
NLP devoted to learning approaches is known as Natural Language Learning (NLL) and its conference CoNLL and peak body SIGNLL
approaches is known as Natural Language Learning (NLL)
Natural Language Learning (NLL)
Natural Language Learning (NLL)
NLL)
its conference CoNLL and peak body SIGNLL
SIGNLL
ACL
their links with Computational Linguistics and Language Acquisition
Computational Linguistics and Language Acquisition
Computational Linguistics and Language Acquisition
Language Acquisition
the aims of computational language learning research is to understand more about human language acquisition , or psycholinguistics
the aims of computational language learning research
computational language learning research
computational language learning research
research
more about human language acquisition , or psycholinguistics
human language acquisition , or psycholinguistics
human language acquisition , or psycholinguistics
psycholinguistics
NLL overlaps into the related field of Computational Psycholinguistics .
the related field of Computational Psycholinguistics
the related field of Computational Psycholinguistics
Computational Psycholinguistics
